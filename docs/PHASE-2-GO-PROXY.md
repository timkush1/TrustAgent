# Phase 2: Go Interceptor Proxy - Complete Guide

> **Status**: âœ… Complete and Working  
> **Tests**: 16/16 Passing  
> **Ports**: 8080 (HTTP), 8081 (WebSocket)  
> **Audience**: Junior developers learning the codebase

---

## Table of Contents

1. [Overview](#1-overview)
2. [What This Component Does](#2-what-this-component-does)
3. [Architecture](#3-architecture)
4. [Directory Structure](#4-directory-structure)
5. [File-by-File Explanation](#5-file-by-file-explanation)
6. [Request Flow](#6-request-flow)
7. [The TeeWriter Pattern](#7-the-teewriter-pattern)
8. [Worker Pool](#8-worker-pool)
9. [WebSocket Hub](#9-websocket-hub)
10. [Configuration](#10-configuration)
11. [Running the Proxy](#11-running-the-proxy)
12. [Testing](#12-testing)
13. [Common Tasks](#13-common-tasks)
14. [Troubleshooting](#14-troubleshooting)

---

## 1. Overview

The Go Proxy is the **front door** of TruthTable. It sits between your application and the LLM API, intercepting all traffic for auditing.

### Key Technologies

| Technology | Purpose |
|------------|---------|
| Go 1.21+ | Main language (chosen for performance) |
| Gin | HTTP router and middleware |
| gorilla/websocket | WebSocket server for dashboard |
| gRPC | Communication with Python engine |

### Why Go?

- **Performance**: Handles thousands of concurrent connections
- **Low latency**: Critical for a proxy (we can't slow down LLM calls)
- **Goroutines**: Lightweight async processing
- **Small binaries**: Easy deployment

---

## 2. What This Component Does

### The Proxy in One Sentence

Intercepts LLM API requests, forwards them to the real API, captures the response, sends it for auditing, and broadcasts results to the dashboard.

### Key Responsibilities

| Task | How |
|------|-----|
| **Intercept** | Gin HTTP handler at `/v1/chat/completions` |
| **Forward** | Reverse proxy to upstream (OpenAI/Ollama) |
| **Capture** | TeeWriter copies response while streaming |
| **Dispatch** | Worker pool sends to Python via gRPC |
| **Broadcast** | WebSocket hub pushes to dashboards |

### Visual Flow

```
Your App                    Go Proxy                      OpenAI
    â”‚                          â”‚                            â”‚
    â”‚â”€â”€POST /v1/chat/â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                            â”‚
    â”‚                          â”‚â”€â”€Forward requestâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
    â”‚                          â”‚                            â”‚
    â”‚                          â”‚â—€â”€â”€Stream responseâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚â—€â”€â”€Stream to clientâ”€â”€â”€â”€â”€â”€â”€â”‚                            â”‚
    â”‚                          â”‚                            â”‚
    â”‚                          â”‚â”€â”€Async: Send to Pythonâ”€â”€â”€â”€â–¶ Python Engine
    â”‚                          â”‚                            â”‚
    â”‚                          â”‚â—€â”€â”€Result via Redisâ”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                          â”‚                            â”‚
    â”‚                          â”‚â”€â”€WebSocket broadcastâ”€â”€â”€â”€â”€â”€â–¶ Dashboard
```

---

## 3. Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Go Proxy                                   â”‚
â”‚                   (Ports 8080, 8081)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                    HTTP Server (:8080)                    â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚
â”‚   â”‚  â”‚  CORS   â”‚â”€â–¶â”‚  Auth   â”‚â”€â–¶â”‚ Logger  â”‚â”€â–¶â”‚ Handler â”‚     â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                    Handler                                â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚  â”‚
â”‚   â”‚  â”‚ Parse Req   â”‚â”€â–¶â”‚ Proxy + Tee â”‚â”€â–¶â”‚ Queue Audit â”‚       â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                   â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚               â–¼                              â–¼                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚    Worker Pool      â”‚       â”‚   WebSocket Hub     â”‚         â”‚
â”‚   â”‚  (10 goroutines)    â”‚       â”‚     (:8081)         â”‚         â”‚
â”‚   â”‚                     â”‚       â”‚                     â”‚         â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”‚       â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”‚         â”‚
â”‚   â”‚  â”‚ W â”‚ â”‚ W â”‚ â”‚ W â”‚ â”‚       â”‚  â”‚ C â”‚ â”‚ C â”‚ â”‚ C â”‚ â”‚         â”‚
â”‚   â”‚  â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â”‚       â”‚  â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚              â”‚                              â”‚                    â”‚
â”‚              â–¼                              â”‚                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚                    â”‚
â”‚   â”‚    gRPC Client      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚   â”‚  (to Python:50051)  â”‚                                        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Directory Structure

```
backend-go/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ proxy/
â”‚       â””â”€â”€ main.go              # Entry point - wires everything together
â”‚
â”œâ”€â”€ internal/                    # Private packages (Go convention)
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.go            # Environment-based configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ proxy/
â”‚   â”‚   â”œâ”€â”€ handler.go           # HTTP handlers (main logic)
â”‚   â”‚   â””â”€â”€ handler_test.go      # Unit tests
â”‚   â”‚
â”‚   â”œâ”€â”€ worker/
â”‚   â”‚   â”œâ”€â”€ pool.go              # Worker pool for async audit
â”‚   â”‚   â””â”€â”€ pool_test.go         # Unit tests
â”‚   â”‚
â”‚   â”œâ”€â”€ grpc/
â”‚   â”‚   â””â”€â”€ client.go            # gRPC client to Python engine
â”‚   â”‚
â”‚   â”œâ”€â”€ websocket/
â”‚   â”‚   â”œâ”€â”€ hub.go               # WebSocket connection manager
â”‚   â”‚   â””â”€â”€ hub_test.go          # Unit tests
â”‚   â”‚
â”‚   â”œâ”€â”€ buffer/                  # Response buffering
â”‚   â””â”€â”€ metrics/                 # Prometheus metrics
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ audit/
â”‚       â””â”€â”€ v1/
â”‚           â”œâ”€â”€ evaluator.pb.go       # Generated protobuf types
â”‚           â””â”€â”€ evaluator_grpc.pb.go  # Generated gRPC client
â”‚
â”œâ”€â”€ go.mod                       # Go module definition
â”œâ”€â”€ go.sum                       # Dependency checksums
â””â”€â”€ Dockerfile                   # Container build
```

---

## 5. File-by-File Explanation

### 5.1 Entry Point: `cmd/proxy/main.go`

**Location**: `cmd/proxy/main.go`

**Purpose**: Initializes all components and starts servers.

**What it does**:
1. Loads configuration from environment
2. Connects to Python gRPC server
3. Creates worker pool
4. Sets up WebSocket hub
5. Configures Gin router
6. Starts HTTP server (8080) and WebSocket server (8081)
7. Handles graceful shutdown

**Key code structure**:
```go
func main() {
    // 1. Load config
    cfg := config.Load()
    
    // 2. Connect to Python audit engine
    auditClient, err := grpc.NewAuditClient(cfg.GRPCAddress)
    
    // 3. Create WebSocket hub
    wsHub := websocket.NewHub()
    go wsHub.Run()
    
    // 4. Create worker pool
    workerPool := worker.NewPool(cfg.WorkerCount, auditClient, wsHub)
    go workerPool.Start()
    
    // 5. Create HTTP handler
    handler := proxy.NewHandler(cfg.UpstreamURL, workerPool)
    
    // 6. Setup Gin router
    router := gin.Default()
    router.POST("/v1/chat/completions", handler.HandleChatCompletion)
    router.GET("/health", handler.HealthCheck)
    
    // 7. Start WebSocket server (separate port)
    go startWebSocketServer(wsHub, cfg.WSPort)
    
    // 8. Start HTTP server
    router.Run(":" + cfg.Port)
}
```

---

### 5.2 Configuration: `internal/config/config.go`

**Location**: `internal/config/config.go`

**Purpose**: Loads settings from environment variables.

**Key settings**:
```go
type Config struct {
    // Server
    Port       string        // HTTP port (default: 8080)
    WSPort     string        // WebSocket port (default: 8081)
    
    // Upstream LLM
    UpstreamURL string       // Where to forward requests (default: https://api.openai.com)
    
    // Python gRPC
    GRPCAddress string       // Python engine address (default: localhost:50051)
    GRPCTimeout time.Duration // Audit timeout (default: 30s)
    
    // Worker Pool
    WorkerCount int          // Number of concurrent workers (default: 10)
    QueueSize   int          // Max pending audits (default: 1000)
}
```

**Environment variables**:
```bash
TRUTHTABLE_PORT=8080
TRUTHTABLE_WS_PORT=8081
TRUTHTABLE_UPSTREAM_URL=https://api.openai.com
TRUTHTABLE_GRPC_ADDRESS=localhost:50051
TRUTHTABLE_WORKER_COUNT=10
```

---

### 5.3 HTTP Handler: `internal/proxy/handler.go`

**Location**: `internal/proxy/handler.go`

**Purpose**: Handles incoming HTTP requests, proxies to upstream, captures response.

**Key methods**:

| Method | Purpose |
|--------|---------|
| `HandleChatCompletion` | Main handler for `/v1/chat/completions` |
| `handleStreamingResponse` | Handles SSE streaming responses |
| `handleNonStreamingResponse` | Handles regular JSON responses |
| `handleTestResponse` | Handles test mode (no real API call) |

**HandleChatCompletion flow**:
```go
func (h *Handler) HandleChatCompletion(c *gin.Context) {
    // 1. Generate request ID
    requestID := uuid.New().String()
    
    // 2. Read and parse request body
    bodyBytes, _ := io.ReadAll(c.Request.Body)
    var chatReq ChatCompletionRequest
    json.Unmarshal(bodyBytes, &chatReq)
    
    // 3. Extract prompt for auditing
    prompt := extractPrompt(chatReq.Messages)
    
    // 4. Check for test mode
    if chatReq.TestResponse != "" {
        h.handleTestResponse(c, requestID, prompt, chatReq)
        return
    }
    
    // 5. Forward to upstream
    // ... proxy logic ...
    
    // 6. Handle streaming or non-streaming
    if chatReq.Stream {
        h.handleStreamingResponse(c, resp, requestID, prompt, chatReq)
    } else {
        h.handleNonStreamingResponse(c, resp, requestID, prompt, chatReq)
    }
}
```

---

### 5.4 Worker Pool: `internal/worker/pool.go`

**Location**: `internal/worker/pool.go`

**Purpose**: Manages goroutines that process audit jobs asynchronously.

**Why a worker pool?**
- We can't block user responses waiting for audits
- We need to limit concurrent gRPC calls
- We need graceful shutdown

**Structure**:
```go
type Pool struct {
    workers     int                  // Number of worker goroutines
    queue       chan *AuditJob       // Buffered channel as queue
    auditClient *grpc.AuditClient    // gRPC client
    wsHub       *websocket.Hub       // For broadcasting results
    wg          sync.WaitGroup       // For graceful shutdown
    ctx         context.Context      // For cancellation
}

type AuditJob struct {
    RequestID string
    Prompt    string
    Response  string
    Model     string
    Timestamp time.Time
}
```

**How it works**:
```go
// Submit adds a job to the queue (non-blocking)
func (p *Pool) Submit(job *AuditJob) {
    select {
    case p.queue <- job:
        log.Printf("[%s] Job submitted", job.RequestID)
    default:
        // Queue full - drop job (fail-open)
        log.Printf("[%s] Queue full, dropping", job.RequestID)
    }
}

// Worker goroutine (10 of these running)
func (p *Pool) worker(id int) {
    for {
        select {
        case <-p.ctx.Done():
            return  // Shutdown
        case job := <-p.queue:
            p.processJob(id, job)
        }
    }
}

// Process a single job
func (p *Pool) processJob(workerID int, job *AuditJob) {
    // 1. Call Python via gRPC
    result, err := p.auditClient.Evaluate(job)
    
    // 2. Broadcast to WebSocket clients
    p.wsHub.BroadcastAuditResult(result)
}
```

---

### 5.5 WebSocket Hub: `internal/websocket/hub.go`

**Location**: `internal/websocket/hub.go`

**Purpose**: Manages WebSocket connections and broadcasts messages to all clients.

**The Hub Pattern**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WebSocket Hub                    â”‚
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Client 1 â”‚  â”‚ Client 2 â”‚  â”‚ Client 3 â”‚  ...    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚       â–²              â–²              â–²              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                      â”‚                             â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚   Broadcast   â”‚                     â”‚
â”‚              â”‚    Channel    â”‚                     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key methods**:
```go
type Hub struct {
    clients    map[*Client]bool  // Connected clients
    broadcast  chan []byte       // Messages to broadcast
    register   chan *Client      // New connections
    unregister chan *Client      // Disconnections
}

// Run processes all hub events (runs in own goroutine)
func (h *Hub) Run() {
    for {
        select {
        case client := <-h.register:
            h.clients[client] = true
            log.Printf("Client connected (total: %d)", len(h.clients))
            
        case client := <-h.unregister:
            delete(h.clients, client)
            close(client.send)
            log.Printf("Client disconnected (total: %d)", len(h.clients))
            
        case message := <-h.broadcast:
            for client := range h.clients {
                select {
                case client.send <- message:
                    // Sent successfully
                default:
                    // Client buffer full, disconnect
                    delete(h.clients, client)
                    close(client.send)
                }
            }
        }
    }
}

// BroadcastAuditResult sends result to all connected dashboards
func (h *Hub) BroadcastAuditResult(result *AuditResult) {
    msg := WSMessage{
        Type:      "audit_result",
        Timestamp: time.Now().Format(time.RFC3339),
        Data:      result,
    }
    data, _ := json.Marshal(msg)
    h.broadcast <- data
}
```

---

### 5.6 gRPC Client: `internal/grpc/client.go`

**Location**: `internal/grpc/client.go`

**Purpose**: Communicates with the Python audit engine.

**Key methods**:
```go
type AuditClient struct {
    conn   *grpc.ClientConn
    client pb.AuditServiceClient
}

// Evaluate sends an audit request and waits for result
func (c *AuditClient) Evaluate(ctx context.Context, requestID, prompt, response string) (*AuditResult, error) {
    // 1. Submit the audit
    submission, err := c.client.SubmitAudit(ctx, &pb.AuditRequest{
        RequestId: requestID,
        Query:     prompt,
        Response:  response,
    })
    
    // 2. Poll for result
    for i := 0; i < 30; i++ {
        result, err := c.client.GetAuditResult(ctx, &pb.AuditResultRequest{
            AuditId: submission.AuditId,
        })
        
        if result.Status == pb.AuditStatus_COMPLETED {
            return convertResult(result), nil
        }
        
        time.Sleep(500 * time.Millisecond)
    }
    
    return nil, fmt.Errorf("audit timed out")
}
```

---

## 6. Request Flow

### Complete Sequence

```
1. Client sends POST /v1/chat/completions
         â”‚
         â–¼
2. Gin router matches handler
         â”‚
         â–¼
3. HandleChatCompletion:
   a. Parse request JSON
   b. Extract prompt from messages
   c. Check for test_response (test mode)
         â”‚
         â–¼
4. If test mode:
   a. Create fake response
   b. Submit audit job
   c. Return fake response to client
         â”‚
   If real mode:
   a. Forward to upstream (OpenAI)
   b. Stream response to client via TeeWriter
   c. Capture full response
   d. Submit audit job
         â”‚
         â–¼
5. Worker pool picks up job
         â”‚
         â–¼
6. Worker calls Python via gRPC
         â”‚
         â–¼
7. Python returns audit result
         â”‚
         â–¼
8. Worker broadcasts to WebSocket hub
         â”‚
         â–¼
9. Hub sends to all connected dashboards
```

### Timing Diagram

```
Time â†’
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶

Client          Go Proxy              OpenAI           Python
  â”‚                â”‚                     â”‚                â”‚
  â”‚â”€â”€Requestâ”€â”€â”€â”€â”€â”€â–¶â”‚                     â”‚                â”‚
  â”‚                â”‚â”€â”€Forwardâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                â”‚
  â”‚                â”‚â—€â”€Chunk 1â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
  â”‚â—€â”€Chunk 1â”€â”€â”€â”€â”€â”€â”€â”‚                     â”‚                â”‚
  â”‚                â”‚â—€â”€Chunk 2â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
  â”‚â—€â”€Chunk 2â”€â”€â”€â”€â”€â”€â”€â”‚                     â”‚                â”‚
  â”‚                â”‚â—€â”€[DONE]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
  â”‚â—€â”€[DONE]â”€â”€â”€â”€â”€â”€â”€â”€â”‚                     â”‚                â”‚
  â”‚                â”‚                     â”‚                â”‚
  â”‚                â”‚â”€â”€â”€â”€â”€gRPC Submitâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
  â”‚                â”‚                     â”‚                â”‚
  â”‚                â”‚â—€â”€â”€â”€â”€Audit Resultâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚                â”‚                     â”‚                â”‚
  â”‚                â”‚â”€â”€WebSocketâ”€â”€â–¶ Dashboard              â”‚
```

---

## 7. The TeeWriter Pattern

### The Problem

When streaming responses from OpenAI:
- We need to send chunks to the client immediately (low latency)
- We also need to capture the full response for auditing
- We can only read the stream once

### The Solution: TeeWriter

```go
// TeeWriter writes to client AND captures for later
type TeeWriter struct {
    http.ResponseWriter        // Original writer (to client)
    buffer *bytes.Buffer       // Capture buffer
    mu     sync.Mutex          // Thread safety
}

func (t *TeeWriter) Write(p []byte) (int, error) {
    t.mu.Lock()
    t.buffer.Write(p)          // Capture
    t.mu.Unlock()
    
    return t.ResponseWriter.Write(p)  // Send to client
}

func (t *TeeWriter) CapturedBody() string {
    return t.buffer.String()   // Get captured data
}
```

### Visual Explanation

```
                    TeeWriter
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚              â”‚
         â–¼              â”‚              â–¼
    To Client           â”‚         To Buffer
    (immediate)         â”‚         (capture)
         â”‚              â”‚              â”‚
         â–¼              â”‚              â–¼
    User sees           â”‚         For audit
    response            â”‚         later
```

---

## 8. Worker Pool

### Why Worker Pool?

1. **Non-blocking**: User response isn't delayed by audit
2. **Rate limiting**: Control concurrent gRPC calls
3. **Resilience**: Queue absorbs traffic spikes
4. **Graceful shutdown**: Complete pending work before exit

### Pool Configuration

| Setting | Default | Purpose |
|---------|---------|---------|
| `WorkerCount` | 10 | Concurrent audit workers |
| `QueueSize` | 1000 | Max pending jobs |

### Fail-Open Design

```go
// If queue is full, drop the audit job (don't block user)
func (p *Pool) Submit(job *AuditJob) {
    select {
    case p.queue <- job:
        // Success - job queued
    default:
        // Queue full - log and continue
        log.Printf("Queue full, dropping audit for %s", job.RequestID)
        metrics.DroppedAudits.Inc()
    }
}
```

**Philosophy**: The user's request is more important than the audit. If we're overloaded, we drop audits rather than slow down users.

---

## 9. WebSocket Hub

### Message Types

```go
type WSMessage struct {
    Type      string      `json:"type"`       // Message type
    Timestamp string      `json:"timestamp"`  // ISO 8601
    Data      interface{} `json:"data"`       // Payload
}
```

| Type | Payload | When Sent |
|------|---------|-----------|
| `connected` | Client ID | On connection |
| `audit_result` | AuditResult | When audit completes |
| `error` | Error message | On error |

### Client Connection Flow

```
1. Dashboard opens WebSocket to ws://localhost:8081/ws
         â”‚
         â–¼
2. Hub receives connection, adds to clients map
         â”‚
         â–¼
3. Hub sends "connected" message to client
         â”‚
         â–¼
4. Client is now subscribed to all broadcasts
         â”‚
         â–¼
5. When audit completes, hub broadcasts to ALL clients
```

---

## 10. Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `TRUTHTABLE_PORT` | 8080 | HTTP server port |
| `TRUTHTABLE_WS_PORT` | 8081 | WebSocket port |
| `TRUTHTABLE_UPSTREAM_URL` | https://api.openai.com | LLM API URL |
| `TRUTHTABLE_GRPC_ADDRESS` | localhost:50051 | Python engine |
| `TRUTHTABLE_GRPC_TIMEOUT` | 30s | Audit timeout |
| `TRUTHTABLE_WORKER_COUNT` | 10 | Worker goroutines |
| `TRUTHTABLE_QUEUE_SIZE` | 1000 | Max queued audits |

### Example Configuration

```bash
# For development
export TRUTHTABLE_PORT=8080
export TRUTHTABLE_UPSTREAM_URL=http://localhost:11434  # Ollama
export TRUTHTABLE_GRPC_ADDRESS=localhost:50051

# For production
export TRUTHTABLE_PORT=8080
export TRUTHTABLE_UPSTREAM_URL=https://api.openai.com
export TRUTHTABLE_GRPC_ADDRESS=python-audit:50051
export TRUTHTABLE_WORKER_COUNT=50
```

---

## 11. Running the Proxy

### Development Mode

```bash
cd backend-go
go run ./cmd/proxy
```

Expected output:
```
ğŸš€ Starting TruthTable Proxy
   Server Port: 8080
   WebSocket Port: 8081
   Upstream URL: https://api.openai.com
   gRPC Address: localhost:50051
âœ“ Connected to audit engine at localhost:50051
âœ“ WebSocket hub started
âœ“ Worker pool started (10 workers)
âœ… TruthTable Proxy is ready!
   Send requests to: http://localhost:8080/v1/chat/completions
   Dashboard WebSocket: ws://localhost:8081/ws
```

### Build and Run Binary

```bash
cd backend-go

# Build
go build -o proxy ./cmd/proxy

# Run
./proxy
```

### Verify It's Running

```bash
# Health check
curl http://localhost:8080/health
# {"status":"ok"}

# Check ports
lsof -i:8080
lsof -i:8081
```

---

## 12. Testing

### Run All Tests

```bash
cd backend-go
go test ./... -v
```

Expected output:
```
=== RUN   TestTeeWriter_CapturesWhileWriting
--- PASS: TestTeeWriter_CapturesWhileWriting (0.00s)
=== RUN   TestHandler_ExtractsPrompt
--- PASS: TestHandler_ExtractsPrompt (0.00s)
=== RUN   TestWorkerPool_SubmitsJob
--- PASS: TestWorkerPool_SubmitsJob (0.01s)
=== RUN   TestHub_BroadcastsToClients
--- PASS: TestHub_BroadcastsToClients (0.00s)
...
PASS
ok      github.com/truthtable/backend-go/internal/proxy     0.15s
ok      github.com/truthtable/backend-go/internal/worker    0.12s
ok      github.com/truthtable/backend-go/internal/websocket 0.08s
```

### Run Specific Package

```bash
# Just proxy tests
go test ./internal/proxy/... -v

# Just websocket tests
go test ./internal/websocket/... -v
```

### Test Coverage

```bash
go test ./... -coverprofile=coverage.out
go tool cover -html=coverage.out
```

---

## 13. Common Tasks

### Adding a New Endpoint

1. Add handler method in `internal/proxy/handler.go`:
```go
func (h *Handler) MyNewEndpoint(c *gin.Context) {
    // Implementation
    c.JSON(200, gin.H{"status": "ok"})
}
```

2. Register route in `cmd/proxy/main.go`:
```go
router.GET("/my-endpoint", handler.MyNewEndpoint)
```

### Modifying WebSocket Messages

Edit `internal/websocket/hub.go`:
```go
type MyNewMessage struct {
    Type string `json:"type"`
    // Add fields
}

func (h *Hub) BroadcastMyMessage(data MyData) {
    msg := MyNewMessage{Type: "my_type", ...}
    h.broadcast <- marshal(msg)
}
```

### Changing Worker Pool Size

Environment variable:
```bash
export TRUTHTABLE_WORKER_COUNT=20
```

Or modify default in `internal/config/config.go`.

---

## 14. Troubleshooting

### Problem: "Could not connect to audit engine"

```
âš ï¸ Warning: Could not connect to audit engine at localhost:50051
```

**Solution**: Start Python engine first
```bash
cd backend-python
python -m truthtable.main
```

### Problem: "Address already in use"

```
Error: listen tcp :8080: bind: address already in use
```

**Solution**:
```bash
# Find and kill process
lsof -ti:8080 | xargs kill -9

# Or use different port
TRUTHTABLE_PORT=9090 go run ./cmd/proxy
```

### Problem: "WebSocket clients disconnect immediately"

**Cause**: Often CORS or proxy configuration issue

**Solution**: Check CORS settings in Gin:
```go
router.Use(cors.New(cors.Config{
    AllowOrigins:     []string{"http://localhost:5173"},
    AllowMethods:     []string{"GET", "POST"},
    AllowWebSockets:  true,
}))
```

### Problem: "Audit queue full"

```
[req-123] Worker queue full, dropping audit job
```

**Solution**: Increase queue size or worker count:
```bash
export TRUTHTABLE_QUEUE_SIZE=5000
export TRUTHTABLE_WORKER_COUNT=20
```

### Problem: "gRPC timeout"

```
[req-123] Audit failed: context deadline exceeded
```

**Solution**: 
1. Check Python engine is running
2. Increase timeout: `TRUTHTABLE_GRPC_TIMEOUT=60s`
3. Check Ollama is responding (LLM might be slow)

---

## Summary

The Go Proxy:
1. âœ… Intercepts LLM requests on port 8080
2. âœ… Forwards to upstream (OpenAI/Ollama)
3. âœ… Captures responses using TeeWriter
4. âœ… Dispatches audits via worker pool
5. âœ… Communicates with Python via gRPC
6. âœ… Broadcasts results via WebSocket

**16 tests passing** - the proxy is production-ready.

---

*Next: Read [PHASE-3-REACT-DASHBOARD.md](PHASE-3-REACT-DASHBOARD.md) to understand the React Dashboard.*
